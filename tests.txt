These are things that I need to test:

- can mulitple input files be accepted?
- can input files with more than necessary columns be accepted and properly processed?
- does the script write to the correct output directory?


Questions I have:

- do I care about the clustering method? aka should I save its name?



Notes from meeting with Artem

spend at least of half oteh presentation setting the stage. pick either mcmicro or sms to present.

assess how well clustering worked by looking at 
- a heatmap or clustergram. this is used only on max several hundred features/cells
- t- SNE. its difficult to know how valid resutls are because perplexity parameter changes things so much
- UMAP is best. load in log transformed expression data and then color with the cluster assignments from the different methods and see if they match the UMAP clusters well



So it seems like the way to do this is to divide your dataset as you go assigning clusters to end up with an NlogN complexity.
So like every time I assign a cell to a cluster, I divide the dataset to those that are in the same cluster as that one? something like that because if I know that cell 1 is 
in the same cluster as cell 3 and cell 2 is in the same cluster as cell 3 then I know that cell 2 and cell 1 are in the same cluster without ever having to compare them.



I can really easily make clusters by grouping duplicate rows. I then just have to make a single comparison between all those groups (because all cells within each group are the same)!
That will tell me how similar all those cells are to each other. bruh I should just make a new data structure: cluster.

cluster:
    vars:
    - cluster numbers from each method
    - list of cell IDs in this cluster
    - dictionary where each key is a cluster and value is the similarity between them

        example:

            cluster A: (0, 4, 5, 1)
            cluster B: (0, 3, 5, 1)

            so in this case all cells in cluster A would have a consensus score of 0.75 with all cells in cluster B.